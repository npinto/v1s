# create/activate virtualenv
virtualenv plos08_reprod
cd plos08_reprod
export PJT=$(pwd)
source bin/activate
mkdir src data

# -- get caltech101 image set

cd $PJT/data
wget http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz
tar xzvf 101_ObjectCategories.tar.gz 

# -- reproducing with 'v1s' from tarball

# get v1s plos08 original source code
cd $PJT/src
wget http://pinto.scripts.mit.edu/uploads/Research/v1s-0.0.5.tar.gz
tar xzvf v1s-0.0.5.tar.gz

# assumption: gcc-4.2, PIL, numpy and scipy are installed (with atlas/blas support)

# get old pyml (compatible with v1s-0.0.5)
cd $PJT/src
wget http://downloads.sourceforge.net/project/pyml/pyml/0.7.0/PyML-0.7.0.tar.gz
tar xzvf PyML-0.7.0.tar.gz
cd PyML-0.7.0
CXX=g++-4.2 CC=gcc-4.2 python setup.py build
python setup.py install

# run v1s code
cd $PJT/src/v1s-0.0.5
python ./v1s_run.py params_simple.py $PJT/data/101_ObjectCategories

#All scores:
# (1)  57.42
# (2)  58.60
# (3)  58.67
# (4)  57.09
# (5)  57.15
# (6)  57.46
# (7)  57.97
# (8)  58.38
# (9)  58.29
# (10)  57.86
#--------------------------------------------------------------------------------
#10 Average: 57.89 (std=0.56, stderr=0.18)
#================================================================================

# -- reproducing with 'v1like' and 'sclas' (github)

# get v1like and sclas
cd $PJT/src
git clone https://github.com/npinto/v1like.git
git clone https://github.com/npinto/sclas.git
export V1LIKE=$PJT/src/v1like
export SCLAS=$PJT/src/sclas

# don't forget to install shogun
# e.g. see: https://github.com/npinto/np-toolbox/blob/master/install_scripts/install_shogun0.9.3_Ubuntu9.10.bash

# create splits
for i in `seq -w 1 10`; do python $SCLAS/create_traintest_split.py --rseed=$i --ntrain=15 --ntest=15 $PJT/data/101_ObjectCategories/{,train15test15_split_${i}.csv}; done;

# generate v1like features
export NPROCS=$(cat /proc/cpuinfo | grep processor | wc -l)
export conf=v1like_a
for i in `seq -w 1 10`; do python $V1LIKE/v1like_extract_fromcsv.py --nprocessors=$NPROCS -i $PJT/data/101_ObjectCategories/ $V1LIKE/config/$conf.py $PJT/data/101_ObjectCategories/train15test15_split_${i}.csv $conf.mat; done;

# generate kernels
for csv in $PJT/data/101_ObjectCategories/train15test15_split_??.csv; do python $SCLAS/kernel_generate_fromcsv.py -i $(dirname $csv) $csv $conf.mat $csv.kernel.$conf.mat; done;

# run SVMs
for csv in $PJT/data/101_ObjectCategories/train15test15_split_??.csv; do python $SCLAS/svm_ova_fromfilenames.py $csv.kernel.$conf.mat -o $csv.svm_ova_results.$conf.mat; done;

# average results (crudely ;-)
for i in `seq -w 1 10`; do python $SCLAS/print_mat.py $PJT/data/101_ObjectCategories/train15test15_split_${i}.csv.svm_ova_results.$conf.mat accuracy; done | awk '{sum+=$2} END {print sum/NR}';

# 57.8366

# EO
